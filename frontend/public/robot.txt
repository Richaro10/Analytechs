# robots.txt â€“ Fichier pour les moteurs de recherche
# ğŸ“ Ce fichier indique ce que les robots dâ€™indexation (Googlebot, Bingbotâ€¦) peuvent explorer ou non sur votre site

# ğŸ‘‰ Autoriser tous les robots Ã  tout explorer
User-agent: *
Allow: /

# ğŸ‘‰ SpÃ©cification du sitemap dynamique gÃ©nÃ©rÃ© via Strapi
Sitemap: https://analytechs.tech/api/sitemap.xml

# ğŸ‘‰ Ajout du flux RSS (utile pour Google News & agrÃ©gateurs)
# (ğŸ’¡ ce nâ€™est pas une directive officielle, mais reconnu par certains services)
RSS: https://analytechs.tech/api/rss.xml

# ğŸ’¡ Autres directives possibles (optionnelles) :
# Disallow: /admin/
# Disallow: /private/
# Crawl-delay: 10

# ğŸ“Œ Si tu souhaites interdire certaines zones du site Ã  lâ€™indexation :
# Disallow: /api/ (Ã©vite dâ€™indexer les routes techniques Strapi)
